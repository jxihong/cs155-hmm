{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from sklearn.externals import joblib\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = joblib.load('../models/hmm_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6751"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = model.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "O = model.emissionprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_start = model.startprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = json.load(open('../models/shakespeare_words/shakespeare_vocab.json'))\n",
    "\n",
    "for k in vocab.keys():\n",
    "    vocab[int(k)] = vocab.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_vocab = json.load(open('../models/shakespeare_words/shakespeare_inverted_vocab.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../models/shakespeare_words/shakespeare_meter.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-aa5b14846325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/shakespeare_words/shakespeare_meter.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minverted_meter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/shakespeare_words/shakespeare_inverted_meter.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/shakespeare_words/shakespeare_pos.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minverted_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/shakespeare_words/shakespeare_inverted_pos.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/word2vec.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../models/shakespeare_words/shakespeare_meter.json'"
     ]
    }
   ],
   "source": [
    "meter = json.load(open('../models/shakespeare_words/shakespeare_meter.json'))\n",
    "inverted_meter = json.load(open('../models/shakespeare_words/shakespeare_inverted_meter.json'))\n",
    "pos = json.load(open('../models/shakespeare_words/shakespeare_pos.json'))\n",
    "inverted_pos = json.load(open('../models/shakespeare_words/shakespeare_inverted_pos.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec.load('../models/word2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_pick(l, probs):\n",
    "    \"\"\" \n",
    "    Probabilistic random picking according\n",
    "    to a probability distribution\n",
    "    \"\"\"\n",
    "    x = random.uniform(0, 0.999)\n",
    "    cumulative_probability = 0.0\n",
    "\n",
    "    for item, prob in zip(l, probs):\n",
    "        cumulative_probability += prob\n",
    "        if x < cumulative_probability: \n",
    "            break\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L, D = O.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"NN\" in inverted_pos[\"ear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_next(num_syllables, previous_word, probs):\n",
    "    new_probs = np.copy(probs)\n",
    "    \n",
    "    # Filter based on meter, and keep syllables 11 or under\n",
    "    invalid = []\n",
    "    for k in meter.keys():\n",
    "        m = map(int, k.split(','))\n",
    "        if m[0] != num_syllables % 2:\n",
    "            invalid.extend([inverted_vocab[w] for w in meter[k]])\n",
    "        \n",
    "        if len(m) + num_syllables > 10:\n",
    "            invalid.extend([inverted_vocab[w] for w in meter[k]])\n",
    "    if \"NN\" in inverted_pos[previous_word]:\n",
    "        for k in pos.keys():\n",
    "            if k not in [\"VB\",\"RB\",\"IN\"]:\n",
    "                invalid.extend([inverted_vocab[w] for w in pos[k]])\n",
    "    if \"VB\" in inverted_pos[previous_word]:\n",
    "        for k in pos.keys():\n",
    "            if k in [\"VB\"]:\n",
    "                invalid.extend([inverted_vocab[w] for w in pos[k]])\n",
    "            \n",
    "    new_probs[invalid] = 0\n",
    "    with np.errstate(divide='ignore'):\n",
    "        new_probs = np.divide(new_probs, np.sum(new_probs))\n",
    "        \n",
    "        new_probs[new_probs == np.inf] = 0\n",
    "        new_probs = np.nan_to_num(new_probs)\n",
    "    \n",
    "    \n",
    "    return new_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_line(start_word):\n",
    "    emission = []\n",
    "    \n",
    "    num_syllables = 0    \n",
    "        \n",
    "    start = inverted_vocab[start_word]\n",
    "    state = random_pick(range(L), \\\n",
    "                    np.divide(O[:, start], np.sum(O[:, start])))\n",
    "            \n",
    "    num_syllables += len(inverted_meter[start_word][0].split(','))\n",
    "    emission.append(start_word)\n",
    "\n",
    "    prev_word = start_word\n",
    "    while num_syllables < 10:\n",
    "        # Sample next observation.\n",
    "        next_probs = filter_next(num_syllables, prev_word, O[state, :])    \n",
    "        next_obs= random_pick(range(D), next_probs)\n",
    "            \n",
    "        try:\n",
    "            next_word = vocab[next_obs]    \n",
    "            if (next_word == \"'\"): # This somehow showed up as word, skip\n",
    "                continue\n",
    "                \n",
    "            emission.append(next_word)\n",
    "            stresses = inverted_meter[next_word][0].split(',')\n",
    "            \n",
    "            num_syllables += len(stresses)\n",
    "            prev_word = next_word\n",
    "            \n",
    "            next_state = random_pick(range(L), A[state, :])\n",
    "            state = next_state\n",
    "                \n",
    "        except KeyError: # shouldn't occur, but just in case\n",
    "            continue\n",
    "                \n",
    "    return emission\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def start_next(prev_start):\n",
    "    w, p = zip(*word2vec.most_similar(prev_start, topn=30))\n",
    "\n",
    "    w = list(w)\n",
    "    # Make sure it starts out with unstressed\n",
    "    starts = []\n",
    "    for word in w:\n",
    "        stresses = inverted_meter[word][0].split(',')\n",
    "        if (stresses[0] == '0'):\n",
    "            starts.append(word)\n",
    "    \n",
    "    if len(starts) == 0:\n",
    "        return prev_start\n",
    "    return np.random.choice(starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sonnet(start_word):\n",
    "    sonnet = ''\n",
    "    for i in xrange(14):\n",
    "        line = generate_line(start_word)\n",
    "        sonnet += ' '.join(line)\n",
    "        if ((i + 1) % 4 == 0) or (i == 13):\n",
    "            sonnet += '.\\n'\n",
    "        else:\n",
    "            sonnet += ',\\n'\n",
    "            \n",
    "        start_word = start_next(start_word)\n",
    "    return sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years takes of nothing never stain'd than waste,\n",
      "torment for my infection so his fiend,\n",
      "incertainties with brief for fire of me,\n",
      "directed watery exclaiming my.\n",
      "betrays compared time-beguiling words,\n",
      "dissolve deceased imprison'd not the face,\n",
      "'yet and it long solicited for red,\n",
      "vehement my besieged for thy below.\n",
      "confirmed the tears of a deceits with a,\n",
      "importune changing orator is more,\n",
      "repine than thy if presently attend,\n",
      "possessed arise gather'd or themes with thee.\n",
      "authority against it but with and,\n",
      "oppressed of when aside deprived account.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print generate_sonnet('years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rhyme = json.load(open('../models/shakespeare_words/shakespeare_rhyme.json'))\n",
    "\n",
    "inverted_rhyme = json.load( \\\n",
    "            open('../models/shakespeare_words/shakespeare_inverted_rhyme.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1,0']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_meter[\"changing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 0.7026592493057251),\n",
       " ('eyes', 0.6991778016090393),\n",
       " ('heart', 0.6895580291748047),\n",
       " ('make', 0.6819394826889038),\n",
       " ('yet', 0.6790560483932495),\n",
       " ('one', 0.6719660758972168),\n",
       " ('sweet', 0.6665604114532471),\n",
       " ('may', 0.6648432612419128),\n",
       " ('whose', 0.6574447154998779),\n",
       " ('would', 0.6525707840919495)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
